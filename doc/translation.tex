\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{cyrtimes}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=3cm,right=1.5cm,top=2cm,bottom=2cm]{geometry}
\usepackage[titletoc]{appendix}
\usepackage{multicol}
\usepackage{multirow}
\usepackage[labelsep=endash]{caption}

\pdfcompresslevel=9

\begin{document}

\section{МЕТОДОЛОГИЯ}

В этом пункте мы опишем числовые данные и как они используются для кластеризации и 
обнаружения атак. Сначала мы исследуем, что представляют из себя эти данные, какие
ключевые признаки можно выделить и какие типы атак они представляют. Затем будет
описано как данные были нормализованы на основании среднеквадратичного отклонения
для обучающей выборки представленных числовых данных, так чтобы система была универсальной
и могла обучаться на разных типах входных данных. Позже следует описание метрики и 
собственно сам алгоритм кластеризации. В завершение приводятся методы пометки кластеров
и классификации ранее неизвестных векторов.

\subsection{ОПИСАНИЕ ЧИСЛОВЫХ ДАННЫХ}
В качестве числовых данных были использованы KDD Cup 1999 Data, которые содержат
широкий спектр атак, смоделированных в компьютерной сети, используемой в вооруженных
силах. Мощность выборки около 4 900 000, каждый элемент выборки представляет собой
вектор признаков для отдельно взятого сетевого соединения (network connection),
полученного из "сырых" сетевых данных, собранных во время моделирования атак.
Под соединением понимается последовательность TCP пакетов от получателя к отправителю,
которые в свою очередь идентифицируются при помощи IP-адресов. TCP пакеты были собраны
в соединения при помощи программы Bro \cite{bib:bro}, модифицированной для работы с
MADAM/ID \cite{bib:madamid}. Каждое соединение было помечено либо нормальным, либо
аномальным с меткой типа атаки. Предполагается, что все метки правильные.

Смоделированные атаки попали в одну из четырех категорий: DoS - отказ в обслуживании,
R2L - удаленное проникновение, L2R - локальное проникновение и Probing - сканирование
(сетевое или сканирование уязвимостей). Всего было смоделировано 24 типа атак.

Ключевые признаки соединений включали в себя как базовые признаки TCP соединений, таких
как длительность соединения, тип протокола, число переданных байт и статус соединения.
Другие признаки были получены с использованием знаний предметной области и включали в себя
число операций по созданию файлов, число неуспешных попыток авторизации и другие. Также
было несколько признаков, вычисленных при помощи окна длительностью в 2 секунды. Среди них -
число подключений к узлу в сети в рамках текущего соединения на протяжении последних 2х секунд,
процент соединений с флагами ошибок SYN и REJ, и число подключений к сервису в сети в рамках
текущего соединения за последние 2 секунды. Суммарно получился 41 признак, большинство из которых
принимают непрерывные значения.

\subsection{НОРМАЛИЗАЦИЯ}

Для того, чтобы алгоритм был универсальным, он должен быть применим для разных типо числовых данных,
подаваемых на вход. Обычно с числовыми данными возникает проблема разнородность представленных в ней
признаков векторов: разные признаки могут принимать значения из разных диапазонов. Это может повлечь
за собой то, что некоторые признаки будут иметь больший вклад чем другие.

Например, возьмём 2 вектора длины 3: $\{(1,3000,2),(1,4000,3)\}$. Евклидово расстояние между этими векторами
будет $(1-1)^2 + (3000-4000)^2 + (2-3)^2$ -- доминируется 2ой компонентой векторов.

Для решения этой проблемы, мы конвертируем все векторы согласно распределению векторов в обучающей выборке.
При этом мы предполагаем, что обучающая выборка должным образом отражает диапазон значений и отклонение
значений признаков всей выборки. Поэтому мы можем масштабировать все данные на заранее фиксированный нами
промежуток и выбирать диаметр кластера на основании выбранного промежутка.

Пусть имеется обучающая выборка $M_{tr}$. Выборочное среднее и стандартное отклонение для векторов выборки:

$$\textit{avg\_vector}[j] = \frac{1}{N} \sum_{i=1}^N \textit{instance}_i[j]$$


$$\textit{std\_vector}[j] = (\frac{1}{N-1} \sum_{i=1}^N (\textit{instance}_i[j] - \textit{avg\_vector}[j])^2)^{1/2}$$

где $\textit{vector}[j]$ - $j$-ый признак (компонента) для $\textit{vector}$.

Каждый вектор теперь преобразуется следующим образом:

$$\textit{new\_instance}[j] = \frac{\textit{instance}[j] - \textit{avg\_vector}[j]}{\textit{std\_vector}[j]}$$


Таким способ преобразуются только признаки с непрерывными значениями. Символьные остаются неизменными.

Это и есть масштабирование векторов из всей числовой выборки в промежуток, определяемый на основе
статистической информации, полученной из обучающей выборки.

\subsection{КЛАСТЕРИЗАЦИЯ}

Для создания кластеров на основе входных числовых данных использовался упрощённый вариант single-linkage
кластеризации (метод одиночной связи или метод ближайшего соседа). Хотя это и не самый эффективный алгоритм
кластеризации, у него есть весомое преимущество: алгоритмическая сложность близка к $O(n)$. Алгоритм
разбивает множество входных числовых данных на кластеры за один проход, начиная с пустого множества кластеров
и заканчивая конечным разбиение. Для каждого нормализованного вектора обучающей выборки находится расстояние до
центроидов всех сгенерированных на данный момент кластеров. Из всех кластеров выбирается ближайший, и если расстояние
до него меньше некоторой константы $W$ (диаметр кластера), то вектор относят к этому кластеру. В противном случае
создаётся новый кластер с указанным вектором в качестве центроида. Более формально алгоритм описан ниже.

Предположим мы выбрали метрику $M$ и зафиксировали диаметр кластера $W$. 
Пусть $dist(C, d)$, где $C$ - кластер, $d$ - вектор, --- расстояние по метрике
$M$ между вектором $d$ и вектором, представляющим кластер $C$.
Представляющим вектором для кластера является вектор признаков, который определяет
центр кластера. Будем называть такой представляющий вектор \textit{центроидом}.

\begin{enumerate}

\item Инициализировать множество кластеров $S = \emptyset $

\item Взять вектор признаков $d$ из обучающего множества. Если $S$ пусто, то создать
кластер с вектором $d$ в качестве представляющего для этого кластера, и добавить
созданный кластер в множество $S$. В противном случае найти среди кластеров
 множества $S$ ближайший к $d$. Другими словами, найти кластер $C \in S$, такой что 
 $\forall C_1 \in S, dist(C, d) \leq dist(C_1, d)$.
 
\item Если $dist(C, d) \leq W$, то добавить вектор $d$ в кластер $C$. В противном 
случае, $d$ отстоит более чем на расстояние $\geq W$ от каждого кластера из $S$,
и поэтому для вектора $d$ необходимо создать новый кластер: 
$S \longleftarrow S \cup \left\{C_n\right\}$, где $C_n$ -- кластер, для которого
вектор $d$ является представляющим.

\item Повторить шаги 2 и 3 для всех векторов из обучающего множества

\end{enumerate}

\subsection{ПОМЕТКА КЛАСТЕРОВ}

Зафиксировав метрику $M$, векторы одинакового типа должны находиться 
ближе друг к другу нежели к векторам другого типа. При правильном выборе
диаметра кластера $W$ в результате кластеризации мы получим множество кластеров, 
в каждом из которых находятся векторы только одного типа. Это соотвествует нашему
второму предположению о данных, которое заключается в качественном различии
нормальных векторов и аномальных векторов.

Учитывая, что мы имеем дело с непомеченными данными, мы не располагаем информацией
о типе вектора (нормальный или аномальный) во время обучения. Поэтому необходимо
найти способ определения классификации кластеров на нормальные и аномальные.
Наше первое предположение о данных заключалось в количественном превосходстве
нормальных вектором над аномальными (> 98 \%) в обучающей выборке. Следовательно, 
велика вероятность того, что нормальные кластеры будут содержать много больше векторов, 
чем аномальные. Таким образом, будем помечать некоторый процент $N$ от общего 
числа кластеров нормальными. Остальные кластеры получат метки аномальных.

С таким подходом может возникнуть небольшая проблема, в зависимости от того,
сколько подтипов для нормальных векторов существует в обучающей выборке.
Может существовать много различных типов векторов нормального поведения
в сети. Взять для примера векторы для разных протоколов - ftp, telnet, http, ssh и др.
Каждый из них может иметь свою точку в пространстве признаков, около которых
будут формироваться кластеры. Это может привести к образованию большого
числа таких <<нормальных>> кластеров для каждого нормального поведения в сети.
Каждый из таких кластеров будет иметь мощность относительно малую по сравнению с 
аномальными кластерами. И в результате этого, нормальные кластеры будут ошибочно
отнесены к аномальным. Для предотвращения такой проблемы необходимо обеспечить
количественное превосходство нормальных векторов в обучающей выборке над
аномальными. Тогда высока вероятность того, что каждый тип нормального поведения
будет адекватно представлен кластером по сравнению с кластерами для аномальных
векторов.

\subsection{ОБНАРУЖЕНИЕ}

После кластеризации векторов обучающей выборки система готова проивзодить
обнаружение атак. Пусть на вход поступает вектор $d$. Классификация происходит
следующим образом:

\begin{enumerate}

\item Конвертировать $d$ на основе статистической информации об обучающей выборке,
из которой были сформированы кластеры (нормализация). Обозначим полученный вектор $d'$

\item Найти кластер, ближайший к $d'$ по метрике $M$ (т.е. такой кластер $C \in S$, что
$\forall C' \in S : dist(C, d') \leq dist(C',d')$)

\item Классифицировать $d'$ согласно типу кластера (нормальный или аномальный)

\end{enumerate}

Другими словами, мы находим кластер, ближайший к вектору $d$ (нормализованному) и
классифицируем его согласно типу этого кластера.


\section{ОЦЕНКА СИСТЕМЫ И РЕЗУЛЬТАТЫ}

\subsection{ОЦЕНКА ЭФФЕКТИВНОСТИ}

Для оценки построенной системы существуют 2 главных индикатора эффективности: \textit{
коэффициент обнаружения} и \textit{коэффициент ложных срабатываний}.

$$\textit{коэффициент обнаружения}=\frac{\textit{число обнаруженных атак}}{\textit{число атак
в тестовой выборке}}$$

$$\textit{коэффициент ложных срабатываний}=\frac{\textit{число нормальных векторов, 
отнесенных к атакам}}{\textit{число нормальных векторов}}$$

Эти 2 параметра являются хорошими индикаторами эффективности, т.к. они позволяют измерить
какой процент атак система способна обнаружить и какой процент неправильных классификаций.
Для оценки эффективности нашей системы мы определяем значения этих параметров на основе
помеченных числовых данных.

\subsection{ФИЛЬТРАЦИЯ ОБУЧАЮЩЕЙ ВЫБОРКИ}

Числовые данные KDD Cup 1999 были получены при помощи моделирования различных типов атак,
с нормальной сетевой активностью на фоне. Целью было сгенерировать обучающую выборку для методов
обучения с учителем, которые используют классифицированные данные. В результате процент аномальных
векторов в обучающей выборке KDD очень велик по сравнению с тем, что наблюдается на практике.

Напомним, что наше второе предположение об обучающей выборке заключается в том, что процент 
аномальных векторов в ней достаточно низок и почти все векторы являются нормальными. Поэтому
числовые данные из KDD Cup в таком виде, в котором они предоставляются, нам не подходят.
Для удовлетрения наших требований числовые данные были отфильтрованы, так что процент атак
составил от 1 до 1.5 \%, а на нормальные векторы пришлось соотвественно от 98.5 до 99 \% от
мощности всей выборки.

\subsection{ОЦЕНКА ПАРАМЕТРОВ}

Для измерения эффективности необходимо предварительно зафиксировать 2 параметра. Первый параметр -
это диаметр кластера $W$, необходимый для проведения кластеризации. С помощью него определяется принадлежность
векторов одному кластеру либо разным. Второй параметр - процент самых больших по мощности кластеров $N$,
которые будут помечены как нормальные во время фазы обнаружения. Целью было присвоить этим параметрам такие
значение, чтобы коэффициенты оценки эффективности имели максимальное значение.

Для определения параметров $W$ и $N$ была использована часть от всего множества числовых данных KDD (10 \%).
Над этими числовыми данными была проведена серия тестов с целью измерения результирующей эффективности.
Множество для проведения этих экспериментов выбиралось так, чтобы быть репрезентативным для всего множества
числовых данных: в него попали вектора для разных типов атак.

После нахождения значений для диаметра кластера $W$ и $N$, которые максимизировали бы коэффициенты эффективности
для выбранного множества, они были зафиксированы для всех последующих экспериментов с различными множествами
входных данных. Эти 2 параметра были зафиксированы с целью оценки значений максимальных эффективностей для
имеющихся типов входных данных. Диаметр кластера - оценка, позволяющия оценить в среднем расстояние в пространстве
признаков между векторами кластера, имеющими один и тот же тип. Эта оценка является отличительной особенностью
предметной области -- характеристика сетевого соединения. Число $N$ также является характеристикой сети - оно
предназначено для оценки процента подтипов норманых векторов по отношению к общему числу различных подтипов.

При фиксировании значений диаметра кластера $W$ и процента нормальных кластеров $N$, проведя измерения коэффициентов
эффективности для различных пар обучающая выборка/тестовая выборка, получили результаты, которые представлены в таблице \ref{table:fix_width}.

\begin{table}
	\caption{Test table 2}
	\label{table:fix_width}
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
		\hline

		\hline
		\multirow{2}{*}{\textbf{W}} & \multirow{2}{*}{\textbf{N}} & \multicolumn{2}{|l|}{\textbf{\hspace{45pt}Коэффициент}} \\
		& & \multicolumn{1}{|c|}{\textbf{обнаружения}} & \multicolumn{1}{|c|}{\textbf{ложных срабатываний}} \\
		\hline 20 & 15 \% & 35.7 \% & 1.44 \% \\
		\hline 20 & 7 \% & 66.2 \% & 2.7 \% \\
		\hline 20 & 2 \% & 88 \% & 8.14 \% \\
		\hline

		\hline
		\end{tabular}
	\end{center}
\end{table}


Для $N$ было выбрано значение 15\%, т.к. при таком значении процента нормальных кластеров получаем приемлемой значение коэффициента ложных срабатываний и при этом не сильно жертвуем коэффициентом обнаружения. 

Для нахождения значения $W$ было также проведено несколько измерений для фиксированных комбинации обучающей выборки и тестовой выборки, значения $N$. Результаты некоторых из этих измерений приведены в таблице \ref{table:fix_n}.

\begin{table}
	\caption{Test table 3}
	\label{table:fix_n}
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
		\hline

		\hline
		\multirow{2}{*}{\textbf{W}} & \multirow{2}{*}{\textbf{N}} & \multicolumn{2}{|l|}{\textbf{\hspace{45pt}Коэффициент}} \\
		& & \multicolumn{1}{|c|}{\textbf{обнаружения}} & \multicolumn{1}{|c|}{\textbf{ложных срабатываний}} \\
		\hline 30 & 15 \% & 28.1  \% & 1.07 \% \\
		\hline 40 & 15 \% & 30.77 \% & 0.84 \% \\
		\hline 60 & 15 \% & 31.9  \% & 0.7  \% \\
		\hline 80 & 15 \% & 22.84 \% & 0.6  \% \\
		\hline

		\hline
		\end{tabular}
	\end{center}
\end{table}


Значение диаметра кластера $W$ было в итоге выбрано равным $40$, при том что при $W=60$ казалось бы значения коэффициентов были лучше, чем при $W=40$. Однако многочисленные тесты показали, что при $W=60$ эффективность ниже, чем при $W=40$.

На рисунке \ref{fig:roc_curve} показана \textit{ROC-кривая}\footnote{ROC-кривая (англ. receiver operating characteristic, операционная характеристика приёмника) — график, позволяющий оценить качество бинарной классификации, отображает соотношение между долей верных положительных классификаций от общего числа положительных классификаций (англ. true positive rate, $TPR$, называемой чувствительностью алгоритма классификации) с долей ошибочных положительных классификаций от общего числа отрицательных классификаций 
(англ. false positive rate, $FPR$, величина $1-FRP$ называется специфичностью алгоритма классификации) при варьировании порога решающего правила \cite{bib:wiki_roc} }, отражающая зависимость между введенными коэффициентами измерения эффективности для одной фиксированной комбинации обучающей и тестовой выборки.

\subsection{ПЕРЕКРЕСТНАЯ ПРОВЕРКА}

После того, как все необходимые параметры были зафиксированы, была проведена оценка системы с использованием перекрестной
проверки\footnote{Перекрёстная проверка (англ. Cross-validation) — метод оценки аналитической модели и её поведения на независимых данных. При оценке модели имеющиеся в наличии данные разбиваются на $k$ частей. Затем на $k-1$ частях данных производится обучение модели,
а оставшаяся часть данных используется для тестирования. Процедура повторяется $k$ раз; в итоге каждая из $k$ частей данных
используется для тестирования. В результате получается оценка эффективности выбранной модели с наиболее равномерным
использованием имеющихся данных \cite{bib:wiki_cross_validation}}. Все множество входных данных KDD было разбито на 10 подмножеств,
каждое мощностью около 490 000 векторов (или 10\% от общего числа). К сожалению, распределение атак во множестве входных
данных KDD оказалось неравномерным, что явилось серьезным препятствием для проведения перекрестной проверки. Многие из этих множеств
включали в себя только атаки какого-то одного типа. Например, 4ое, 5ое, 6ое и 7ое множества содержали только SMURF атаки, а векторы из 8го
множества вообще почти все представляли NEPTUNE атаки. Учитывая тот факт, что мы требуем чтобы в обучающей выборке были представлены
все подтипы как атак, так и нормальных векторов, вышеуказанные множества не были использованы в перекрестной проверке. Для проведения
перекрестной проверки были выбраны только 4 из 10 подмножеств. Эти 4 подмножества включали в себя содержали разнообразные типы атак и
удовлетворяли поставленным нами предположениям о входных данных. Для этих выбранных подмножеств была велика вероятность, что
в результате кластеризации будут получены кластеры, отражающие многие типы атак.

Каждое из выбранных 4х подмножеств было отфильтровано так, чтобы процент атак в каждом из них составлял 1\% от получившейся
из него обучающей выборки. Затем было произведено обучение на обучающей выборке, получено множество кластеров и сохранено.
Далее были произведены измерения эффективности полученной кластеризации путем классификации векторов для каждого из 4х
этих подмножеств (теперь они использованы в качестве тестовых выборок). Этот процесс был произведен для каждого из 4х подмножеств
в качестве обучающей выборки. Результаты показаны в таблице \ref{table:training_test}.

\begin{table}
	\caption{Test table snippet}
	\label{table:training_test}
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
		\hline

		\hline
		\multicolumn{2}{|l|}{\textbf{\hspace{35pt}Выборка}} & \multicolumn{2}{|l|}{\textbf{\hspace{45pt}Коэффициент}}\\

		\multicolumn{1}{|c|}{\textbf{обучающая}} & \multicolumn{1}{|c|}{\textbf{тестовая}} & \multicolumn{1}{|c|}{\textbf{обнаружения}} & \multicolumn{1}{|c|}{\textbf{ложных срабатываний}} \\
		\hline P10 & P1  & 55.7   \% & 0.99  \% \\
		\hline P10 & P2  & 51.04  \% & 1.58  \% \\
		\hline P10 & P3  & 53.01  \% & 1.67  \% \\
		\hline P10 & P10 & 53.39  \% & 1.04  \% \\
		\hline P2  & P1  & 46.3   \% & 0.46  \% \\
		\hline P2  & P2  & 22.0   \% & 0.70  \% \\
		\hline P2  & P3  & 29.3   \% & 2.35  \% \\
		\hline P2  & P10 & 23.0   \% & 9.83  \% \\
		\hline P1  & P1  & 28.3   \% & 4.5  \% \\
		\hline P1  & P2  & 50.5   \% & 1.26  \% \\
		\hline P1  & P3  & 38.5   \% & 3.45  \% \\
		\hline P1  & P10 & 50.4   \% & 11.37 \% \\
		\hline P3  & P1  & 56.25  \% & 0.3  \% \\
		\hline P3  & P2  & 18.56  \% & 0.6  \% \\
		\hline P3  & P3  & 18.75  \% & 0.74  \% \\
		\hline P3  & P10 & 23.0   \% & 1.31  \% \\
		\hline

		\hline
		\end{tabular}
	\end{center}
\end{table}


Тестовые выборки также были отфильтрованы так, чтобы в них было примерно одинаковое число векторов для каждого типа атак. Это было
необходимо для того, чтобы иметь адекватную оценку эффективности, т.к. к примеру если в тестовой выборке 80\% атак одного типа, то
коэффициент обнаружения 81\% будет означать лишь то, что система способна хорошо обнаруживать только атаки этого типа. Если же
тестовая выборка содержит одинаковое число различных типов атак, то коэффициент обнаружения 81\% говорит о том, что система
способна хорошо обнаруживать различные типы атак.


\end{document}
