\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{cyrtimes}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=3cm,right=1.5cm,top=2cm,bottom=2cm]{geometry}
\usepackage[titletoc]{appendix}
\usepackage{multicol}
\usepackage[labelsep=endash]{caption}

\pdfcompresslevel=9

\begin{document}

\section{МЕТОДОЛОГИЯ}

В этом пункте мы опишем числовые данные и как они используются для кластеризации и 
обнаружения атак. Сначала мы исследуем, что представляют из себя эти данные, какие
ключевые признаки можно выделить и какие типы атак они представляют. Затем будет
описано как данные были нормализованы на основании среднеквадратичного отклонения
для обучающей выборки представленных числовых данных, так чтобы система была универсальной
и могла обучаться на разных типах входных данных. Позже следует описание метрики и 
собственно сам алгоритм кластеризации. В завершение приводятся методы пометки кластеров
и классификации ранее неизвестных векторов.

\subsection{ОПИСАНИЕ ЧИСЛОВЫХ ДАННЫХ}
В качестве числовых данных были использованы KDD Cup 1999 Data, которые содержат
широкий спектр атак, смоделированных в компьютерной сети, используемой в вооруженных
силах. Мощность выборки около 4 900 000, каждый элемент выборки представляет собой
вектор признаков для отдельно взятого сетевого соединения (network connection),
полученного из "сырых" сетевых данных, собранных во время моделирования атак.
Под соединением понимается последовательность TCP пакетов от получателя к отправителю,
которые в свою очередь идентифицируются при помощи IP-адресов. TCP пакеты были собраны
в соединения при помощи программы Bro \cite{bib:bro}, модифицированной для работы с
MADAM/ID \cite{bib:madamid}. Каждое соединение было помечено либо нормальным, либо
аномальным с меткой типа атаки. Предполагается, что все метки правильные.

Смоделированные атаки попали в одну из четырех категорий: DoS - отказ в обслуживании,
R2L - удаленное проникновение, L2R - локальное проникновение и Probing - сканирование
(сетевое или сканирование уязвимостей). Всего было смоделировано 24 типа атак.

Ключевые признаки соединений включали в себя как базовые признаки TCP соединений, таких
как длительность соединения, тип протокола, число переданных байт и статус соединения.
Другие признаки были получены с использованием знаний предметной области и включали в себя
число операций по созданию файлов, число неуспешных попыток авторизации и другие. Также
было несколько признаков, вычисленных при помощи окна длительностью в 2 секунды. Среди них -
число подключений к узлу в сети в рамках текущего соединения на протяжении последних 2х секунд,
процент соединений с флагами ошибок SYN и REJ, и число подключений к сервису в сети в рамках
текущего соединения за последние 2 секунды. Суммарно получился 41 признак, большинство из которых
принимают непрерывные значения.

\subsection{НОРМАЛИЗАЦИЯ}

Для того, чтобы алгоритм был универсальным, он должен быть применим для разных типо числовых данных,
подаваемых на вход. Обычно с числовыми данными возникает проблема разнородность представленных в ней
признаков векторов: разные признаки могут принимать значения из разных диапазонов. Это может повлечь
за собой то, что некоторые признаки будут иметь больший вклад чем другие.

Например, возьмём 2 вектора длины 3: $\{(1,3000,2),(1,4000,3)\}$. Евклидово расстояние между этими векторами
будет $(1-1)^2 + (3000-4000)^2 + (2-3)^2$ -- доминируется 2ой компонентой векторов.

Для решения этой проблемы, мы конвертируем все векторы согласно распределению векторов в обучающей выборке.
При этом мы предполагаем, что обучающая выборка должным образом отражает диапазон значений и отклонение
значений признаков всей выборки. Поэтому мы можем масштабировать все данные на заранее фиксированный нами
промежуток и выбирать диаметр кластера на основании выбранного промежутка.

Пусть имеется обучающая выборка $M_{tr}$. Выборочное среднее и стандартное отклонение для векторов выборки:

$$\textit{avg\_vector}[j] = \frac{1}{N} \sum_{i=1}^N \textit{instance}_i[j]$$


$$\textit{std\_vector}[j] = (\frac{1}{N-1} \sum_{i=1}^N (\textit{instance}_i[j] - \textit{avg\_vector}[j])^2)^{1/2}$$

где $\textit{vector}[j]$ - $j$-ый признак (компонента) для $\textit{vector}$.

Каждый вектор теперь преобразуется следующим образом:

$$\textit{new\_instance}[j] = \frac{\textit{instance}[j] - \textit{avg\_vector}[j]}{\textit{std\_vector}[j]}$$


Таким способ преобразуются только признаки с непрерывными значениями. Символьные остаются неизменными.

Это и есть масштабирование векторов из всей числовой выборки в промежуток, определяемый на основе
статистической информации, полученной из обучающей выборки.

\subsection{КЛАСТЕРИЗАЦИЯ}

Для создания кластеров на основе входных числовых данных использовался упрощённый вариант single-linkage
кластеризации (метод одиночной связи или метод ближайшего соседа). Хотя это и не самый эффективный алгоритм
кластеризации, у него есть весомое преимущество: алгоритмическая сложность близка к $O(n)$. Алгоритм
разбивает множество входных числовых данных на кластеры за один проход, начиная с пустого множества кластеров
и заканчивая конечным разбиение. Для каждого нормализованного вектора обучающей выборки находится расстояние до
центроидов всех сгенерированных на данный момент кластеров. Из всех кластеров выбирается ближайший, и если расстояние
до него меньше некоторой константы $W$ (диаметр кластера), то вектор относят к этому кластеру. В противном случае
создаётся новый кластер с указанным вектором в качестве центроида. Более формально алгоритм описан ниже.

Предположим мы выбрали метрику $M$ и зафиксировали диаметр кластера $W$. 
Пусть $dist(C, d)$, где $C$ - кластер, $d$ - вектор, --- расстояние по метрике
$M$ между вектором $d$ и вектором, представляющим кластер $C$.
Представляющим вектором для кластера является вектор признаков, который определяет
центр кластера. Будем называть такой представляющий вектор \textit{центроидом}.

\begin{enumerate}

\item Инициализировать множество кластеров $S = \emptyset $

\item Взять вектор признаков $d$ из обучающего множества. Если $S$ пусто, то создать
кластер с вектором $d$ в качестве представляющего для этого кластера, и добавить
созданный кластер в множество $S$. В противном случае найти среди кластеров
 множества $S$ ближайший к $d$. Другими словами, найти кластер $C \in S$, такой что 
 $\forall C_1 \in S, dist(C, d) \leq dist(C_1, d)$.
 
\item Если $dist(C, d) \leq W$, то добавить вектор $d$ в кластер $C$. В противном 
случае, $d$ отстоит более чем на расстояние $\geq W$ от каждого кластера из $S$,
и поэтому для вектора $d$ необходимо создать новый кластер: 
$S \longleftarrow S \cup \left\{C_n\right\}$, где $C_n$ -- кластер, для которого
вектор $d$ является представляющим.

\item Повторить шаги 2 и 3 для всех векторов из обучающего множества

\end{enumerate}

\subsection{ПОМЕТКА КЛАСТЕРОВ}

Зафиксировав метрику $M$, векторы одинакового типа должны находиться 
ближе друг к другу нежели к векторам другого типа. При правильном выборе
диаметра кластера $W$ в результате кластеризации мы получим множество кластеров, 
в каждом из которых находятся векторы только одного типа. Это соотвествует нашему
второму предположению о данных, которое заключается в качественном различии
нормальных векторов и аномальных векторов.

Учитывая, что мы имеем дело с непомеченными данными, мы не располагаем информацией
о типе вектора (нормальный или аномальный) во время обучения. Поэтому необходимо
найти способ определения классификации кластеров на нормальные и аномальные.
Наше первое предположение о данных заключалось в количественном превосходстве
нормальных вектором над аномальными (> 98 \%) в обучающей выборке. Следовательно, 
велика вероятность того, что нормальные кластеры будут содержать много больше векторов, 
чем аномальные. Таким образом, будем помечать некоторый процент $N$ от общего 
числа кластеров нормальными. Остальные кластеры получат метки аномальных.

С таким подходом может возникнуть небольшая проблема, в зависимости от того,
сколько подтипов для нормальных векторов существует в обучающей выборке.
Может существовать много различных типов векторов нормального поведения
в сети. Взять для примера векторы для разных протоколов - ftp, telnet, http, ssh и др.
Каждый из них может иметь свою точку в пространстве признаков, около которых
будут формироваться кластеры. Это может привести к образованию большого
числа таких <<нормальных>> кластеров для каждого нормального поведения в сети.
Каждый из таких кластеров будет иметь мощность относительно малую по сравнению с 
аномальными кластерами. И в результате этого, нормальные кластеры будут ошибочно
отнесены к аномальным. Для предотвращения такой проблемы необходимо обеспечить
количественное превосходство нормальных векторов в обучающей выборке над
аномальными. Тогда высока вероятность того, что каждый тип нормального поведения
будет адекватно представлен кластером по сравнению с кластерами для аномальных
векторов.

\subsection{ОБНАРУЖЕНИЕ}

После кластеризации векторов обучающей выборки система готова проивзодить
обнаружение атак. Пусть на вход поступает вектор $d$. Классификация происходит
следующим образом:

\begin{enumerate}

\item Конвертировать $d$ на основе статистической информации об обучающей выборке,
из которой были сформированы кластеры (нормализация). Обозначим полученный вектор $d'$

\item Найти кластер, ближайший к $d'$ по метрике $M$ (т.е. такой кластер $C \in S$, что
$\forall C' \in S : dist(C, d') \leq dist(C',d')$)

\item Классифицировать $d'$ согласно типу кластера (нормальный или аномальный)

\end{enumerate}

Другими словами, мы находим кластер, ближайший к вектору $d$ (нормализованному) и
классифицируем его согласно типу этого кластера.


\section{ОЦЕНКА СИСТЕМЫ И РЕЗУЛЬТАТЫ}

\subsection{ОЦЕНКА ЭФФЕКТИВНОСТИ}

Для оценки построенной системы существуют 2 главных индикатора эффективности: \textit{
коэффициент обнаружения} и \textit{коэффициент ложных срабатываний}.

$$\textit{коэффициент обнаружения}=\frac{\textit{число обнаруженных атак}}{\textit{число атак
в тестовой выборке}}$$

$$\textit{коэффициент ложных срабатываний}=\frac{\textit{число нормальных векторов, 
отнесенных к атакам}}{\textit{число нормальных векторов}}$$

Эти 2 параметра являются хорошими индикаторами эффективности, т.к. они позволяют измерить
какой процент атак система способна обнаружить и какой процент неправильных классификаций.
Для оценки эффективности нашей системы мы определяем значения этих параметров на основе
помеченных числовых данных.

\subsection{ФИЛЬТРАЦИЯ ОБУЧАЮЩЕЙ ВЫБОРКИ}

Числовые данные KDD Cup 1999 были получены при помощи моделирования различных типов атак,
с нормальной сетевой активностью на фоне. Целью было сгенерировать обучающую выборку для методов
обучения с учителем, которые используют классифицированные данные. В результате процент аномальных
векторов в обучающей выборке KDD очень велик по сравнению с тем, что наблюдается на практике.

Напомним, что наше второе предположение об обучающей выборке заключается в том, что процент 
аномальных векторов в ней достаточно низок и почти все векторы являются нормальными. Поэтому
числовые данные из KDD Cup в таком виде, в котором они предоставляются, нам не подходят.
Для удовлетрения наших требований числовые данные были отфильтрованы, так что процент атак
составил от 1 до 1.5 \%, а на нормальные векторы пришлось соотвественно от 98.5 до 99 \% от
мощности всей выборки.

\subsection{ОЦЕНКА ПАРАМЕТРОВ}

Для измерения эффективности необходимо предварительно зафиксировать 2 параметра. Первый параметр -
это диаметр кластера $W$, необходимый для проведения кластеризации. С помощью него определяется принадлежность
векторов одному кластеру либо разным. Второй параметр - процент самых больших по мощности кластеров $N$,
которые будут помечены как нормальные во время фазы обнаружения. Целью было присвоить этим параметрам такие
значение, чтобы коэффициенты оценки эффективности имели максимальное значение.

Для определения параметров $W$ и $N$ была использована часть от всего множества числовых данных KDD (10 \%).
Над этими числовыми данными была проведена серия тестов с целью измерения результирующей эффективности.
Множество для проведения этих экспериментов выбиралось так, чтобы быть репрезентативным для всего множества
числовых данных: в него попали вектора для разных типов атак.

После нахождения значений для диаметра кластера $W$ и $N$, которые максимизировали бы коэффициенты эффективности
для выбранного множества, они были зафиксированы для всех последующих экспериментов с различными множествами
входных данных. Эти 2 параметра были зафиксированы с целью оценки значений максимальных эффективностей для
имеющихся типов входных данных. Диаметр кластера - оценка, позволяющия оценить в среднем расстояние в пространстве
признаков между векторами кластера, имеющими один и тот же тип. Эта оценка является отличительной особенностью
предметной области -- характеристика сетевого соединения. Число $N$ также является характеристикой сети - оно
предназначено для оценки процента подтипов норманых векторов по отношению к общему числу различных подтипов.


\end{document}
